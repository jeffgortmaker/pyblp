{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6928cb32",
   "metadata": {},
   "source": [
    "# Micro Moments Tutorial with Automobile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46118395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "\n",
    "import pyblp\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "pyblp.options.digits = 2\n",
    "pyblp.options.verbose = False\n",
    "pyblp.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7556f474",
   "metadata": {},
   "source": [
    "In this tutorial, we'll use data from :ref:`references:Petrin (2002)` to solve the paper's automobile problem. This tutorial is similar to the [first automobile tutorial](blp.ipynb), but exhibits how to incorporate micro moments into estimation.\n",
    "\n",
    "\n",
    "## Loading Data\n",
    "\n",
    "We'll use [pandas](https://pandas.pydata.org/) to load two sets of data:\n",
    "\n",
    "1. `product_data`, which contains prices, shares, and other product characteristics.\n",
    "2. `agent_data`, which contains draws from the distribution of heterogeneity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4d7cbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_ids</th>\n",
       "      <th>clustering_ids</th>\n",
       "      <th>firm_ids</th>\n",
       "      <th>region</th>\n",
       "      <th>jp</th>\n",
       "      <th>eu</th>\n",
       "      <th>q</th>\n",
       "      <th>households</th>\n",
       "      <th>shares</th>\n",
       "      <th>prices</th>\n",
       "      <th>...</th>\n",
       "      <th>supply_instruments6</th>\n",
       "      <th>supply_instruments7</th>\n",
       "      <th>supply_instruments8</th>\n",
       "      <th>supply_instruments9</th>\n",
       "      <th>supply_instruments10</th>\n",
       "      <th>supply_instruments11</th>\n",
       "      <th>supply_instruments12</th>\n",
       "      <th>supply_instruments13</th>\n",
       "      <th>supply_instruments14</th>\n",
       "      <th>supply_instruments15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>EU</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.647</td>\n",
       "      <td>83527</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>10.379538</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>-151.682461</td>\n",
       "      <td>108.724278</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>460.419731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>EU</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.611</td>\n",
       "      <td>83527</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>13.140814</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>-151.682461</td>\n",
       "      <td>108.724278</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>460.419731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>EU</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.139</td>\n",
       "      <td>83527</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>19.746975</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>-151.682461</td>\n",
       "      <td>108.724278</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>460.419731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1981</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>EU</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.553</td>\n",
       "      <td>83527</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>13.085809</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>-151.682461</td>\n",
       "      <td>108.724278</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>460.419731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.198</td>\n",
       "      <td>83527</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>6.660066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>-157.647246</td>\n",
       "      <td>114.055507</td>\n",
       "      <td>30.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>467.806186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   market_ids  clustering_ids  firm_ids region  jp  eu       q  households  \\\n",
       "0        1981               1         7     EU   0   1  18.647       83527   \n",
       "1        1981               2         7     EU   0   1  17.611       83527   \n",
       "2        1981               2         7     EU   0   1   6.139       83527   \n",
       "3        1981               3         7     EU   0   1   2.553       83527   \n",
       "4        1981               4        15     US   0   0  43.198       83527   \n",
       "\n",
       "     shares     prices  ...  supply_instruments6  supply_instruments7  \\\n",
       "0  0.000223  10.379538  ...                  9.0                  0.0   \n",
       "1  0.000211  13.140814  ...                  9.0                  0.0   \n",
       "2  0.000073  19.746975  ...                  9.0                  0.0   \n",
       "3  0.000031  13.085809  ...                  9.0                  0.0   \n",
       "4  0.000517   6.660066  ...                  0.0                  0.0   \n",
       "\n",
       "   supply_instruments8  supply_instruments9  supply_instruments10  \\\n",
       "0                  0.0                144.0           -151.682461   \n",
       "1                  0.0                144.0           -151.682461   \n",
       "2                  0.0                144.0           -151.682461   \n",
       "3                  0.0                144.0           -151.682461   \n",
       "4                  0.0                149.0           -157.647246   \n",
       "\n",
       "   supply_instruments11  supply_instruments12  supply_instruments13  \\\n",
       "0            108.724278                  30.0                  32.0   \n",
       "1            108.724278                  30.0                  32.0   \n",
       "2            108.724278                  30.0                  32.0   \n",
       "3            108.724278                  30.0                  32.0   \n",
       "4            114.055507                  30.0                  35.0   \n",
       "\n",
       "   supply_instruments14  supply_instruments15  \n",
       "0                  32.0            460.419731  \n",
       "1                  32.0            460.419731  \n",
       "2                  32.0            460.419731  \n",
       "3                  32.0            460.419731  \n",
       "4                  42.0            467.806186  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_data = pd.read_csv(pyblp.data.PETRIN_PRODUCTS_LOCATION)\n",
    "product_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ded30c",
   "metadata": {},
   "source": [
    "The `product_data` contains market IDs, product IDs, firm IDs, shares, prices, a number of product characteristics, and instruments. The product IDs are called `clustering_ids` because they will be used to compute clustered standard errors. For more information about the instruments and the example data as a whole, refer to the :mod:`data` module.\n",
    "\n",
    "The `agent_data` contains market IDs, integration weights $w_{it}$, integration nodes $\\nu_{it}$, and demographics $d_{it}$. Here we use $I_t = 1000$ scrambled Halton draws in each market, along with demographics resampled from the Consumer Expenditure Survey (CEX) used by the original paper. These draws are slightly different from those used in the original paper (pseudo Monte Carlo draws and importance sampling). Note that following the original paper, the integration nodes are actually draws from a truncated $\\chi^2(3)$ distribution, rather than the more typical $N(0, 1)$ draws that we have seen in prior tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06a6f43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_ids</th>\n",
       "      <th>weights</th>\n",
       "      <th>nodes0</th>\n",
       "      <th>nodes1</th>\n",
       "      <th>nodes2</th>\n",
       "      <th>nodes3</th>\n",
       "      <th>nodes4</th>\n",
       "      <th>nodes5</th>\n",
       "      <th>fv</th>\n",
       "      <th>income</th>\n",
       "      <th>low</th>\n",
       "      <th>mid</th>\n",
       "      <th>high</th>\n",
       "      <th>fs</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.533314</td>\n",
       "      <td>7.496742</td>\n",
       "      <td>2.649343</td>\n",
       "      <td>3.892549</td>\n",
       "      <td>0.833761</td>\n",
       "      <td>1.928344</td>\n",
       "      <td>0.749785</td>\n",
       "      <td>10.346577</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4.422582</td>\n",
       "      <td>0.858539</td>\n",
       "      <td>1.646447</td>\n",
       "      <td>2.973352</td>\n",
       "      <td>0.033288</td>\n",
       "      <td>1.683242</td>\n",
       "      <td>5.232336</td>\n",
       "      <td>13.944210</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.341509</td>\n",
       "      <td>5.041918</td>\n",
       "      <td>4.118932</td>\n",
       "      <td>2.166338</td>\n",
       "      <td>1.314582</td>\n",
       "      <td>0.360087</td>\n",
       "      <td>1.860212</td>\n",
       "      <td>5.898788</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1981</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3.324113</td>\n",
       "      <td>2.354892</td>\n",
       "      <td>0.802351</td>\n",
       "      <td>0.261043</td>\n",
       "      <td>3.911970</td>\n",
       "      <td>1.027856</td>\n",
       "      <td>6.980909</td>\n",
       "      <td>8.125445</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.895857</td>\n",
       "      <td>1.807990</td>\n",
       "      <td>1.827797</td>\n",
       "      <td>4.080565</td>\n",
       "      <td>1.709768</td>\n",
       "      <td>0.707514</td>\n",
       "      <td>2.450663</td>\n",
       "      <td>34.397295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   market_ids  weights    nodes0    nodes1    nodes2    nodes3    nodes4  \\\n",
       "0        1981    0.001  2.533314  7.496742  2.649343  3.892549  0.833761   \n",
       "1        1981    0.001  4.422582  0.858539  1.646447  2.973352  0.033288   \n",
       "2        1981    0.001  1.341509  5.041918  4.118932  2.166338  1.314582   \n",
       "3        1981    0.001  3.324113  2.354892  0.802351  0.261043  3.911970   \n",
       "4        1981    0.001  1.895857  1.807990  1.827797  4.080565  1.709768   \n",
       "\n",
       "     nodes5        fv     income  low  mid  high  fs  age  \n",
       "0  1.928344  0.749785  10.346577    1    0     0   4    1  \n",
       "1  1.683242  5.232336  13.944210    0    1     0   2    1  \n",
       "2  0.360087  1.860212   5.898788    1    0     0   4    0  \n",
       "3  1.027856  6.980909   8.125445    1    0     0   2    0  \n",
       "4  0.707514  2.450663  34.397295    0    0     1   2    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_data = pd.read_csv(pyblp.data.PETRIN_AGENTS_LOCATION)\n",
    "agent_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04056a2",
   "metadata": {},
   "source": [
    "## Setting up the Problem\n",
    "\n",
    "The problem configuration is based on that of the first automobile problem. It is very similar, with both demand and supply sides, although with a few more product characteristics.\n",
    "\n",
    "Again, we stack the three product formulations in order: $X_1$, $X_2$, and $X_3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "281e3283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1 + hpwt + space + air + mpd + fwd + mi + sw + su + pv + pgnp + trend + trend2,\n",
       " 1 + I(-prices) + hpwt + space + air + mpd + fwd + mi + sw + su + pv,\n",
       " 1 + log(hpwt) + log(wt) + log(mpg) + air + fwd + trend + jp + eu + trend:jp + trend:eu + log(q))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_formulations = (\n",
    "    pyblp.Formulation('1 + hpwt + space + air + mpd + fwd + mi + sw + su + pv + pgnp + trend + trend2'),\n",
    "    pyblp.Formulation('1 + I(-prices) + hpwt + space + air + mpd + fwd + mi + sw + su + pv'),\n",
    "    pyblp.Formulation('1 + log(hpwt) + log(wt) + log(mpg) + air + fwd + trend * (jp + eu) + log(q)'),\n",
    ")\n",
    "product_formulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f682b901",
   "metadata": {},
   "source": [
    "Again, we'll use a first-order linear approximation to $\\log(y_i - p_j)$, in which $y$ is income and $p$ are prices. Unlike the previous automobile problem, however, we'll allow its coefficient to vary for low- mid- and high-income consumers.\n",
    "\n",
    "As in the original paper, we'll also include $log(\\textit{fs}_i) \\times \\textit{fv}_i$ where $\\textit{fs}_i$ is family size and $\\textit{fv}_i$ is another truncated $\\chi^2(3)$ draw. Finally, to help with constructing micro moments below, we'll also include various additional demographics in the agent formulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f059f23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1 + I(low / income) + I(mid / income) + I(high / income) + I(log(fs) * fv) + age + fs + mid + high"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_formulation = pyblp.Formulation('1 + I(low / income) + I(mid / income) + I(high / income) + I(log(fs) * fv) + age + fs + mid + high')\n",
    "agent_formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b51b99",
   "metadata": {},
   "source": [
    "The :class:`Problem` can again be constructed by combining the `product_formulations`, `product_data`, `agent_formulation`, and `agent_data`. We'll again choose a log-linear specification for marginal costs $c_{jt}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "862bdbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dimensions:\n",
       "========================================================\n",
       " T    N     F     I     K1    K2    K3    D    MD    MS \n",
       "---  ----  ---  -----  ----  ----  ----  ---  ----  ----\n",
       "13   2407  27   13000   13    11    12    9    35    28 \n",
       "========================================================\n",
       "\n",
       "Formulations:\n",
       "==============================================================================================================================================\n",
       "       Column Indices:          0       1           2            3           4        5     6     7    8       9         10       11      12  \n",
       "-----------------------------  ---  ----------  ----------  -----------  ----------  ---  -----  ---  ----  --------  --------  ------  ------\n",
       " X1: Linear Characteristics     1      hpwt       space         air         mpd      fwd   mi    sw    su      pv       pgnp    trend   trend2\n",
       "X2: Nonlinear Characteristics   1    -prices       hpwt        space        air      mpd   fwd   mi    sw      su        pv                   \n",
       "X3: Log Cost Characteristics    1   log(hpwt)    log(wt)     log(mpg)       air      fwd  trend  jp    eu   jp*trend  eu*trend  log(q)        \n",
       "       d: Demographics          1   low/income  mid/income  high/income  fv*log(fs)  age   fs    mid  high                                    \n",
       "=============================================================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem = pyblp.Problem(product_formulations, product_data, agent_formulation, agent_data, costs_type='log')\n",
    "problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2b4796",
   "metadata": {},
   "source": [
    "The problem outputs a table of dimensions:\n",
    "\n",
    "- $T$ denotes the number of markets.\n",
    "- $N$ is the length of the dataset (the number of products across all markets).\n",
    "- $F$ denotes the number of firms.\n",
    "- $I = \\sum_t I_t$ is the total number of agents across all markets (1000 draws per market times 13 markets).\n",
    "- $K_1$ is the number of linear demand characteristics.\n",
    "- $K_2$ is the number of nonlinear demand characteristics.\n",
    "- $K_3$ is the number of linear supply characteristics.\n",
    "- $D$ is the number of demographic variables.\n",
    "- $M_D$ is the number of demand instruments, including exogenous regressors.\n",
    "- $M_S$ is the number of supply instruments, including exogenous regressors.\n",
    "\n",
    "The formulations table describes all four formulas for demand-side linear characteristics, demand-side nonlinear characteristics, supply-side characteristics, and demographics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde26d61",
   "metadata": {},
   "source": [
    "## Setting up Micro Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae46e78",
   "metadata": {},
   "source": [
    "Next, we will configure the micro moments that we will be adding to the problem. For background and notation involving micro moments, see :ref:`background:Micro Moments`.\n",
    "\n",
    "Specifically, we will be adding a few more moments that match key statistics computed from the CEX survey of potential automobile consumers. For a tutorial on how to compute optimal micro moments that use all the information in a full micro dataset linking individual choices to demographics, see the [post estimation tutorial](post_estimation.ipynb).\n",
    "\n",
    "To start, we will have to define a :class:`MicroDataset` configuration that contains metadata about the micro dataset/survey. These metadata include a unique name for the dataset indexed by $d$, the number of observations $N_d$, a function that defines survey weights $w_{dijt}$, and if relevant, a subset of markets from which the micro data was sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "878bbae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CEX: 29125 Observations in All Markets"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_dataset = pyblp.MicroDataset(\n",
    "    name=\"CEX\", \n",
    "    observations=29125, \n",
    "    compute_weights=lambda t, p, a: np.ones((a.size, 1 + p.size)),\n",
    ")\n",
    "micro_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b95e675",
   "metadata": {},
   "source": [
    "We called the dataset \"CEX\", defined the number of observations in it, and also defined a lambda function for computing survey weights in a market. The `compute_weights` function has three arguments: the current market's ID $t$, the $J_t$ :class:`Products` inside the market, and the $I_t$ :class:`Agents` inside the market. In this case, we are assuming that each product and agent/consumer type are sampled with equal probability, so we simply return a matrix of ones of shape $I_t \\times (1 + J_t)$. This sets each $w_{dijt} = 1$.\n",
    "\n",
    "By using $1 + J_t$ instead of $J_t$, we are specifying that the micro dataset contains observations of the outside option $j = 0$. If we instead specified a matrix of shape $I_t \\times J_t$, this would be the same as setting the first column equal to all zeros, so that outside choices are not sampled from.\n",
    "\n",
    "We will be matching a few different statistics that were computed from this survey. For convenience, they are packaged in a data file with pyblp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ae456a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E[age | mi]</th>\n",
       "      <td>0.7830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E[fs | mi]</th>\n",
       "      <td>3.8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E[age | sw]</th>\n",
       "      <td>0.7300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E[fs | sw]</th>\n",
       "      <td>3.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E[age | su]</th>\n",
       "      <td>0.7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E[fs | su]</th>\n",
       "      <td>2.9700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E[age | pv]</th>\n",
       "      <td>0.6520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E[fs | pv]</th>\n",
       "      <td>3.4700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E[new | mid]</th>\n",
       "      <td>0.0794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E[new | high]</th>\n",
       "      <td>0.1581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                value\n",
       "E[age | mi]    0.7830\n",
       "E[fs | mi]     3.8600\n",
       "E[age | sw]    0.7300\n",
       "E[fs | sw]     3.1700\n",
       "E[age | su]    0.7400\n",
       "E[fs | su]     2.9700\n",
       "E[age | pv]    0.6520\n",
       "E[fs | pv]     3.4700\n",
       "E[new | mid]   0.0794\n",
       "E[new | high]  0.1581"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_statistics = pd.read_csv(pyblp.data.PETRIN_VALUES_LOCATION, index_col=0)\n",
    "micro_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ae5e74",
   "metadata": {},
   "source": [
    "We will match the average age and family size (\"fs\") conditional on purchasing a minivan (\"mi\"), station wagon (\"sw\"), sport-utility (\"su\"), and full-size passenger van (\"pv\"). We will also match the probability that a consumer actually purchases a new vehicle, conditional on them being mid- and high-income.\n",
    "\n",
    "Each of these statistics is a conditional expectation, which we can rewrite as a ration of unconditional expectations over all consumers. Each of these unconditional expectations is called a :class:`MicroPart` (used to form full micro moments), which we will now configure.\n",
    "\n",
    "Each micro part is an average/expectation in the sample/population over micro values $v_{pijt}$. To match the above micro values, we will need averages/expectations over interactions between agent/family size and dummies for purchasing the different automobile types. These will form the numerators in our conditional expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e377d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mi_part = pyblp.MicroPart(\n",
    "    name=\"E[age_i * mi_j]\", \n",
    "    dataset=micro_dataset, \n",
    "    compute_values=lambda t, p, a: np.outer(a.demographics[:, 5], np.r_[0, p.X2[:, 7]]),\n",
    ")\n",
    "age_sw_part = pyblp.MicroPart(\n",
    "    name=\"E[age_i * sw_j]\", \n",
    "    dataset=micro_dataset, \n",
    "    compute_values=lambda t, p, a: np.outer(a.demographics[:, 5], np.r_[0, p.X2[:, 8]]),\n",
    ")\n",
    "age_su_part = pyblp.MicroPart(\n",
    "    name=\"E[age_i * su_j]\", \n",
    "    dataset=micro_dataset, \n",
    "    compute_values=lambda t, p, a: np.outer(a.demographics[:, 5], np.r_[0, p.X2[:, 9]]),\n",
    ")\n",
    "age_pv_part = pyblp.MicroPart(\n",
    "    name=\"E[age_i * pv_j]\", \n",
    "    dataset=micro_dataset, \n",
    "    compute_values=lambda t, p, a: np.outer(a.demographics[:, 5], np.r_[0, p.X2[:, 10]]),\n",
    ")\n",
    "fs_mi_part = pyblp.MicroPart(\n",
    "    name=\"E[fs_i * mi_j]\", \n",
    "    dataset=micro_dataset, \n",
    "    compute_values=lambda t, p, a: np.outer(a.demographics[:, 6], np.r_[0, p.X2[:, 7]]),\n",
    ")\n",
    "fs_sw_part = pyblp.MicroPart(\n",
    "    name=\"E[fs_i * sw_j]\", \n",
    "    dataset=micro_dataset, \n",
    "    compute_values=lambda t, p, a: np.outer(a.demographics[:, 6], np.r_[0, p.X2[:, 8]]),\n",
    ")\n",
    "fs_su_part = pyblp.MicroPart(\n",
    "    name=\"E[fs_i * su_j]\", \n",
    "    dataset=micro_dataset, \n",
    "    compute_values=lambda t, p, a: np.outer(a.demographics[:, 6], np.r_[0, p.X2[:, 9]]),\n",
    ")\n",
    "fs_pv_part = pyblp.MicroPart(\n",
    "    name=\"E[fs_i * pv_j]\", \n",
    "    dataset=micro_dataset, \n",
    "    compute_values=lambda t, p, a: np.outer(a.demographics[:, 6], np.r_[0, p.X2[:, 10]]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d10a0e",
   "metadata": {},
   "source": [
    "We will also need the denominators, which are simple averages/expectations of purchasing the different types of automobiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c4dd5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_part = pyblp.MicroPart(\n",
    "    name=\"E[mi_j]\", \n",
    "    dataset=micro_dataset, \n",
    "    compute_values=lambda t, p, a: np.outer(a.demographics[:, 0], np.r_[0, p.X2[:, 7]]),\n",
    ")\n",
    "sw_part = pyblp.MicroPart(\n",
    "    name=\"E[sw_j]\", \n",
    "    dataset=micro_dataset, \n",
    "    compute_values=lambda t, p, a: np.outer(a.demographics[:, 0], np.r_[0, p.X2[:, 8]]),\n",
    ")\n",
    "su_part = pyblp.MicroPart(\n",
    "    name=\"E[su_j]\", \n",
    "    dataset=micro_dataset, \n",
    "    compute_values=lambda t, p, a: np.outer(a.demographics[:, 0], np.r_[0, p.X2[:, 9]]),\n",
    ")\n",
    "pv_part = pyblp.MicroPart(\n",
    "    name=\"E[pv_j]\", \n",
    "    dataset=micro_dataset, \n",
    "    compute_values=lambda t, p, a: np.outer(a.demographics[:, 0], np.r_[0, p.X2[:, 10]]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b19c50a",
   "metadata": {},
   "source": [
    "To form our probability that a consumer actually purchases a new vehicle, conditional on them being mid- and high-income, we will also need the following micro parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3cca7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inside_mid_part = pyblp.MicroPart(\n",
    "    name=\"E[1{j > 0} * mid_i]\",\n",
    "    dataset=micro_dataset, \n",
    "    compute_values=lambda t, p, a: np.outer(a.demographics[:, 7], np.r_[0, p.X2[:, 0]]),\n",
    ")\n",
    "inside_high_part = pyblp.MicroPart(\n",
    "    name=\"E[1{j > 0} * high_i]\",\n",
    "    dataset=micro_dataset, \n",
    "    compute_values=lambda t, p, a: np.outer(a.demographics[:, 8], np.r_[0, p.X2[:, 0]]),\n",
    ")\n",
    "mid_part = pyblp.MicroPart(\n",
    "    name=\"E[mid_i]\",\n",
    "    dataset=micro_dataset,\n",
    "    compute_values=lambda t, p, a: np.outer(a.demographics[:, 7], np.r_[1, p.X2[:, 0]]),\n",
    ")\n",
    "high_part = pyblp.MicroPart(\n",
    "    name=\"E[high_i]\",\n",
    "    dataset=micro_dataset,\n",
    "    compute_values=lambda t, p, a: np.outer(a.demographics[:, 8], np.r_[1, p.X2[:, 0]]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ab0910",
   "metadata": {},
   "source": [
    "Finally, we'll put these micro parts together into :class:`MicroMoment`s. Each micro moment is configured to have a name, a value (one of the statistics above), and micro parts that go into it.\n",
    "\n",
    "If our micro moments were simple unconditional expectations, we could just pass a single micro part to each micro moment and be done. However, since our micro moments are functions of multiple micro parts, we have to specify this function. We also have to specify its derivative for computing standard errors and analytic objective gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa4d08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_ratio = lambda v: v[0] / v[1]\n",
    "compute_ratio_gradient = lambda v: [1 / v[1], -v[0] / v[1]**2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb439118",
   "metadata": {},
   "source": [
    "Given our functions that define a conditional expectation and its derivatives, we can form our micro moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfed6012",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_moments = [\n",
    "    pyblp.MicroMoment(\n",
    "        name=\"E[age_i | mi_j]\",\n",
    "        value=0.783, \n",
    "        parts=[age_mi_part, mi_part], \n",
    "        compute_value=compute_ratio, \n",
    "        compute_gradient=compute_ratio_gradient,\n",
    "    ),\n",
    "    pyblp.MicroMoment(\n",
    "        name=\"E[age_i | sw_j]\",\n",
    "        value=0.730, \n",
    "        parts=[age_sw_part, sw_part], \n",
    "        compute_value=compute_ratio, \n",
    "        compute_gradient=compute_ratio_gradient,\n",
    "    ),\n",
    "    pyblp.MicroMoment(\n",
    "        name=\"E[age_i | su_j]\",\n",
    "        value=0.740, \n",
    "        parts=[age_su_part, su_part], \n",
    "        compute_value=compute_ratio, \n",
    "        compute_gradient=compute_ratio_gradient,\n",
    "    ),\n",
    "    pyblp.MicroMoment(\n",
    "        name=\"E[age_i | pv_j]\",\n",
    "        value=0.652, \n",
    "        parts=[age_pv_part, pv_part], \n",
    "        compute_value=compute_ratio, \n",
    "        compute_gradient=compute_ratio_gradient,\n",
    "    ),\n",
    "    pyblp.MicroMoment(\n",
    "        name=\"E[fs_i | mi_j]\",\n",
    "        value=3.86, \n",
    "        parts=[fs_mi_part, mi_part], \n",
    "        compute_value=compute_ratio, \n",
    "        compute_gradient=compute_ratio_gradient,\n",
    "    ),\n",
    "    pyblp.MicroMoment(\n",
    "        name=\"E[fs_i | sw_j]\",\n",
    "        value=3.17, \n",
    "        parts=[fs_sw_part, sw_part], \n",
    "        compute_value=compute_ratio, \n",
    "        compute_gradient=compute_ratio_gradient,\n",
    "    ),\n",
    "    pyblp.MicroMoment(\n",
    "        name=\"E[fs_i | su_j]\",\n",
    "        value=2.97, \n",
    "        parts=[fs_su_part, su_part], \n",
    "        compute_value=compute_ratio, \n",
    "        compute_gradient=compute_ratio_gradient,\n",
    "    ),\n",
    "    pyblp.MicroMoment(\n",
    "        name=\"E[fs_i | pv_j]\",\n",
    "        value=3.47, \n",
    "        parts=[fs_pv_part, pv_part], \n",
    "        compute_value=compute_ratio, \n",
    "        compute_gradient=compute_ratio_gradient,\n",
    "    ),\n",
    "    pyblp.MicroMoment(\n",
    "        name=\"E[1{j > 0} | mid_i]\",\n",
    "        value=0.0794, \n",
    "        parts=[inside_mid_part, mid_part], \n",
    "        compute_value=compute_ratio, \n",
    "        compute_gradient=compute_ratio_gradient,\n",
    "    ),\n",
    "    pyblp.MicroMoment(\n",
    "        name=\"E[1{j > 0} | high_i]\",\n",
    "        value=0.1581, \n",
    "        parts=[inside_high_part, high_part], \n",
    "        compute_value=compute_ratio, \n",
    "        compute_gradient=compute_ratio_gradient,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8443449",
   "metadata": {},
   "source": [
    "## Solving the Problem\n",
    "\n",
    "Like for the first automobile problem, here will will just use the publisehd estimates for $\\Sigma$ and $\\Pi$ starting values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e390ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_sigma = np.diag([3.23, 0, 4.43, 0.46, 0.01, 2.58, 4.42, 0, 0, 0, 0])\n",
    "initial_pi = np.array([\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 7.52, 31.13, 34.49, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0.57, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0.28, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0.31, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0.42, 0, 0, 0, 0],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc23b1c9",
   "metadata": {},
   "source": [
    "Finally, as in the original paper, we'll use `W_type` and `se_type` to cluster by product IDs, which were specified as `clustering_ids` in `product_data`. We will use a simple BFGS optimization routine and slightly loosen the default tolerance of our inner SQUAREM iteration algorithm from `1e-14` to `1e-13` because the tighter tolerance tended to lead to convergence failures for this problem. We also pass our configured `micro_moments` when solving the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df67dc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Problem Results Summary:\n",
       "=======================================================================================================\n",
       "GMM   Objective  Gradient      Hessian         Hessian     Clipped  Weighting Matrix  Covariance Matrix\n",
       "Step    Value      Norm    Min Eigenvalue  Max Eigenvalue  Shares   Condition Number  Condition Number \n",
       "----  ---------  --------  --------------  --------------  -------  ----------------  -----------------\n",
       " 2    +1.8E+02   +4.4E-05     +4.3E-01        +1.3E+03        0         +2.8E+11          +8.1E+07     \n",
       "=======================================================================================================\n",
       "\n",
       "Cumulative Statistics:\n",
       "===========================================================================\n",
       "Computation  Optimizer  Optimization   Objective   Fixed Point  Contraction\n",
       "   Time      Converged   Iterations   Evaluations  Iterations   Evaluations\n",
       "-----------  ---------  ------------  -----------  -----------  -----------\n",
       " 00:26:42       Yes          72           87          10899        33588   \n",
       "===========================================================================\n",
       "\n",
       "Nonlinear Coefficient Estimates (Robust SEs Adjusted for 898 Clusters in Parentheses):\n",
       "================================================================================================================================================================================================================================================\n",
       "Sigma:       1       -prices      hpwt       space        air         mpd         fwd         mi        sw        su        pv     |    Pi:       1      low/income  mid/income  high/income  fv*log(fs)    age        fs       mid       high  \n",
       "-------  ----------  --------  ----------  ----------  ----------  ----------  ----------  --------  --------  --------  --------  |  -------  --------  ----------  ----------  -----------  ----------  --------  --------  --------  --------\n",
       "   1      +3.0E-02                                                                                                                 |     1     +0.0E+00   +0.0E+00    +0.0E+00    +0.0E+00     +0.0E+00   +0.0E+00  +0.0E+00  +0.0E+00  +0.0E+00\n",
       "         (+5.3E-01)                                                                                                                |                                                                                                            \n",
       "                                                                                                                                   |                                                                                                            \n",
       "-prices   +0.0E+00   +0.0E+00                                                                                                      |  -prices  +0.0E+00   +3.9E+00    +1.2E+01    +2.4E+01     +0.0E+00   +0.0E+00  +0.0E+00  +0.0E+00  +0.0E+00\n",
       "                                                                                                                                   |                     (+3.6E-01)  (+1.0E+00)  (+2.4E+00)                                                     \n",
       "                                                                                                                                   |                                                                                                            \n",
       " hpwt     +0.0E+00   +0.0E+00   +1.2E-01                                                                                           |   hpwt    +0.0E+00   +0.0E+00    +0.0E+00    +0.0E+00     +0.0E+00   +0.0E+00  +0.0E+00  +0.0E+00  +0.0E+00\n",
       "                               (+8.1E-01)                                                                                          |                                                                                                            \n",
       "                                                                                                                                   |                                                                                                            \n",
       " space    +0.0E+00   +0.0E+00   +0.0E+00    -9.2E-02                                                                               |   space   +0.0E+00   +0.0E+00    +0.0E+00    +0.0E+00     +0.0E+00   +0.0E+00  +0.0E+00  +0.0E+00  +0.0E+00\n",
       "                                           (+6.1E-01)                                                                              |                                                                                                            \n",
       "                                                                                                                                   |                                                                                                            \n",
       "  air     +0.0E+00   +0.0E+00   +0.0E+00    +0.0E+00    -1.3E+00                                                                   |    air    +0.0E+00   +0.0E+00    +0.0E+00    +0.0E+00     +0.0E+00   +0.0E+00  +0.0E+00  +0.0E+00  +0.0E+00\n",
       "                                                       (+1.1E+00)                                                                  |                                                                                                            \n",
       "                                                                                                                                   |                                                                                                            \n",
       "  mpd     +0.0E+00   +0.0E+00   +0.0E+00    +0.0E+00    +0.0E+00    -1.6E-01                                                       |    mpd    +0.0E+00   +0.0E+00    +0.0E+00    +0.0E+00     +0.0E+00   +0.0E+00  +0.0E+00  +0.0E+00  +0.0E+00\n",
       "                                                                   (+2.2E-01)                                                      |                                                                                                            \n",
       "                                                                                                                                   |                                                                                                            \n",
       "  fwd     +0.0E+00   +0.0E+00   +0.0E+00    +0.0E+00    +0.0E+00    +0.0E+00    +1.6E+00                                           |    fwd    +0.0E+00   +0.0E+00    +0.0E+00    +0.0E+00     +0.0E+00   +0.0E+00  +0.0E+00  +0.0E+00  +0.0E+00\n",
       "                                                                               (+3.7E-01)                                          |                                                                                                            \n",
       "                                                                                                                                   |                                                                                                            \n",
       "  mi      +0.0E+00   +0.0E+00   +0.0E+00    +0.0E+00    +0.0E+00    +0.0E+00    +0.0E+00   +0.0E+00                                |    mi     +0.0E+00   +0.0E+00    +0.0E+00    +0.0E+00     +4.2E-01   +0.0E+00  +0.0E+00  +0.0E+00  +0.0E+00\n",
       "                                                                                                                                   |                                                          (+5.2E-02)                                        \n",
       "                                                                                                                                   |                                                                                                            \n",
       "  sw      +0.0E+00   +0.0E+00   +0.0E+00    +0.0E+00    +0.0E+00    +0.0E+00    +0.0E+00   +0.0E+00  +0.0E+00                      |    sw     +0.0E+00   +0.0E+00    +0.0E+00    +0.0E+00     +1.7E-01   +0.0E+00  +0.0E+00  +0.0E+00  +0.0E+00\n",
       "                                                                                                                                   |                                                          (+4.2E-02)                                        \n",
       "                                                                                                                                   |                                                                                                            \n",
       "  su      +0.0E+00   +0.0E+00   +0.0E+00    +0.0E+00    +0.0E+00    +0.0E+00    +0.0E+00   +0.0E+00  +0.0E+00  +0.0E+00            |    su     +0.0E+00   +0.0E+00    +0.0E+00    +0.0E+00     +1.0E-01   +0.0E+00  +0.0E+00  +0.0E+00  +0.0E+00\n",
       "                                                                                                                                   |                                                          (+5.2E-02)                                        \n",
       "                                                                                                                                   |                                                                                                            \n",
       "  pv      +0.0E+00   +0.0E+00   +0.0E+00    +0.0E+00    +0.0E+00    +0.0E+00    +0.0E+00   +0.0E+00  +0.0E+00  +0.0E+00  +0.0E+00  |    pv     +0.0E+00   +0.0E+00    +0.0E+00    +0.0E+00     +2.5E-01   +0.0E+00  +0.0E+00  +0.0E+00  +0.0E+00\n",
       "                                                                                                                                   |                                                          (+8.1E-02)                                        \n",
       "================================================================================================================================================================================================================================================\n",
       "\n",
       "Beta Estimates (Robust SEs Adjusted for 898 Clusters in Parentheses):\n",
       "==========================================================================================================================================================\n",
       "    1          hpwt       space        air         mpd         fwd          mi          sw          su          pv         pgnp       trend       trend2  \n",
       "----------  ----------  ----------  ----------  ----------  ----------  ----------  ----------  ----------  ----------  ----------  ----------  ----------\n",
       " -8.9E+00    +8.3E+00    +4.9E+00    +3.8E+00    -1.4E-01    -6.5E+00    -2.1E+00    -1.3E+00    -1.1E+00    -3.3E+00    +3.4E-02    +2.2E-01    -1.5E-02 \n",
       "(+1.4E+00)  (+2.4E+00)  (+1.6E+00)  (+1.2E+00)  (+3.2E-01)  (+1.8E+00)  (+4.8E-01)  (+2.0E-01)  (+2.8E-01)  (+5.2E-01)  (+1.2E-02)  (+9.2E-02)  (+6.4E-03)\n",
       "==========================================================================================================================================================\n",
       "\n",
       "Gamma Estimates (Robust SEs Adjusted for 898 Clusters in Parentheses):\n",
       "==============================================================================================================================================\n",
       "    1       log(hpwt)    log(wt)     log(mpg)      air         fwd        trend         jp          eu       jp*trend    eu*trend     log(q)  \n",
       "----------  ----------  ----------  ----------  ----------  ----------  ----------  ----------  ----------  ----------  ----------  ----------\n",
       " +1.4E+00    +8.8E-01    +1.4E+00    +1.2E-01    +2.7E-01    +6.9E-02    -1.2E-02    +1.0E-01    +4.6E-01    +1.6E-03    -1.1E-02    -6.9E-02 \n",
       "(+1.4E-01)  (+4.9E-02)  (+8.0E-02)  (+6.0E-02)  (+2.4E-02)  (+1.8E-02)  (+2.6E-03)  (+2.5E-02)  (+4.3E-02)  (+2.9E-03)  (+4.2E-03)  (+6.7E-03)\n",
       "==============================================================================================================================================\n",
       "\n",
       "Estimated Micro Moments:\n",
       "===========================================================================================================\n",
       "Observed  Estimated  Difference         Moment                 Part          Dataset  Observations  Markets\n",
       "--------  ---------  ----------  --------------------  --------------------  -------  ------------  -------\n",
       "+7.8E-01  +7.5E-01    +2.9E-02     E[age_i | mi_j]       E[age_i * mi_j]       CEX       29125        All  \n",
       "                                                             E[mi_j]           CEX       29125        All  \n",
       "+7.3E-01  +6.8E-01    +4.7E-02     E[age_i | sw_j]       E[age_i * sw_j]       CEX       29125        All  \n",
       "                                                             E[sw_j]           CEX       29125        All  \n",
       "+7.4E-01  +6.8E-01    +5.9E-02     E[age_i | su_j]       E[age_i * su_j]       CEX       29125        All  \n",
       "                                                             E[su_j]           CEX       29125        All  \n",
       "+6.5E-01  +7.3E-01    -7.7E-02     E[age_i | pv_j]       E[age_i * pv_j]       CEX       29125        All  \n",
       "                                                             E[pv_j]           CEX       29125        All  \n",
       "+3.9E+00  +3.9E+00    -1.2E-02      E[fs_i | mi_j]        E[fs_i * mi_j]       CEX       29125        All  \n",
       "                                                             E[mi_j]           CEX       29125        All  \n",
       "+3.2E+00  +3.2E+00    -7.6E-03      E[fs_i | sw_j]        E[fs_i * sw_j]       CEX       29125        All  \n",
       "                                                             E[sw_j]           CEX       29125        All  \n",
       "+3.0E+00  +3.0E+00    -8.5E-03      E[fs_i | su_j]        E[fs_i * su_j]       CEX       29125        All  \n",
       "                                                             E[su_j]           CEX       29125        All  \n",
       "+3.5E+00  +3.5E+00    -1.7E-02      E[fs_i | pv_j]        E[fs_i * pv_j]       CEX       29125        All  \n",
       "                                                             E[pv_j]           CEX       29125        All  \n",
       "+7.9E-02  +8.0E-02    -4.5E-04   E[1{j > 0} | mid_i]   E[1{j > 0} * mid_i]     CEX       29125        All  \n",
       "                                                             E[mid_i]          CEX       29125        All  \n",
       "+1.6E-01  +1.6E-01    -2.1E-03   E[1{j > 0} | high_i]  E[1{j > 0} * high_i]    CEX       29125        All  \n",
       "                                                            E[high_i]          CEX       29125        All  \n",
       "==========================================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = problem.solve(\n",
    "    sigma=initial_sigma,\n",
    "    pi=initial_pi,\n",
    "    optimization=pyblp.Optimization('bfgs', {'gtol': 1e-4}),\n",
    "    iteration=pyblp.Iteration('squarem', {'atol': 1e-13}),\n",
    "    se_type='clustered',\n",
    "    W_type='clustered',\n",
    "    micro_moments=micro_moments,\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb2c9f",
   "metadata": {},
   "source": [
    "There are some discrepances between these results and those in the original paper, but broadly estimates are similar. Although the estimates of $\\beta$ looks substantially off, this is primarily because the $\\chi^2(3)$ distributions are not mean-zero, so differences in estimates of $\\Sigma$ results in shifted estimates of $\\beta$ too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5db574",
   "metadata": {},
   "source": [
    "## Running the Main Counterfactual\n",
    "\n",
    "One result that is very similar is the paper's headline number: a \\$367.29 million compensating variation from a counterfactual that removes the minivan in 1984. Using our estimates, we get a very similar number.\n",
    "\n",
    "This subsection previews some of the routines used in the [next tutorial](post_estimation.ipynb) on functions available after estimation. First, we will compute implied marginal costs in 1984."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7db17fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1984\n",
    "costs_1984 = results.compute_costs(market_id=year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1c49d1",
   "metadata": {},
   "source": [
    "Next, we will set up a counterfactual simulation in which the minivan is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c3822e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data_1984 = product_data[product_data['market_ids'] == year]\n",
    "xi_1984 = results.xi[product_data['market_ids'] == year]\n",
    "agent_data_1984 = agent_data[agent_data['market_ids'] == year]\n",
    "simulation = pyblp.Simulation(\n",
    "    product_formulations=product_formulations[:2],\n",
    "    product_data=product_data_1984[product_data_1984['mi'] == 0],\n",
    "    xi=xi_1984[product_data_1984['mi'] == 0],\n",
    "    agent_formulation=problem.agent_formulation,\n",
    "    agent_data=agent_data_1984,\n",
    "    beta=results.beta,\n",
    "    sigma=results.sigma,\n",
    "    pi=results.pi,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c370539",
   "metadata": {},
   "source": [
    "We will then solve for equilibrium prices and shares under this counterfactual, using the above-computed marginal costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c6c0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_results = simulation.replace_endogenous(costs=costs_1984[product_data_1984['mi'] == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50713bb",
   "metadata": {},
   "source": [
    "Finally, we will compute the change in consumer surplus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4d00395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[425.90823299]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "households = product_data_1984['households'].values[0]\n",
    "cs = households * results.compute_consumer_surpluses(market_id=year)\n",
    "counterfactual_cs = households * simulation_results.compute_consumer_surpluses()\n",
    "cs - counterfactual_cs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c6fc9",
   "metadata": {},
   "source": [
    "We get an estimate that is in the same ballpark as \\$367.29 million. When bootstrapping this procedure (see the [next tutorial](post_estimation.ipynb) for more on this), we get a standard error around \\$250 million."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
